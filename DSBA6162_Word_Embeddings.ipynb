{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuIyS2LvsA0GRXntzlPCju",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/owilli38/DSBA-6162/blob/main/DSBA6162_Word_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sROwtIZxukEz",
        "outputId": "ad29d4e6-c5b7-4cbf-9315-26eb19a9e7bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.4.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.0)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqezkNinsCJE",
        "outputId": "3f48a80e-d431-4dcb-85ba-b2a1b392ca98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Import packages\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(action=\"ignore\")#ignore all warning messages in this script\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 1**"
      ],
      "metadata": {
        "id": "Th_HtInb95Z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader\n",
        "list(gensim.downloader.info()[\"models\"].keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJRWIqaBuGK7",
        "outputId": "f757f677-3c32-47e4-d8b4-c264a180f50a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fasttext-wiki-news-subwords-300',\n",
              " 'conceptnet-numberbatch-17-06-300',\n",
              " 'word2vec-ruscorpora-300',\n",
              " 'word2vec-google-news-300',\n",
              " 'glove-wiki-gigaword-50',\n",
              " 'glove-wiki-gigaword-100',\n",
              " 'glove-wiki-gigaword-200',\n",
              " 'glove-wiki-gigaword-300',\n",
              " 'glove-twitter-25',\n",
              " 'glove-twitter-50',\n",
              " 'glove-twitter-100',\n",
              " 'glove-twitter-200',\n",
              " '__testing_word2vec-matrix-synopsis']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_glove_model = gensim.downloader.load(\"glove-wiki-gigaword-50\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srWjjMqDuXWR",
        "outputId": "0b62d505-28af-4fb1-b788-1e025d194f15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78181813",
        "outputId": "42369af7-4ded-4048-f4be-a0258237f63f"
      },
      "source": [
        "seven_words = [\"I\", \"love\", \"deep\", \"learning\", \"and\", \"text\", \"mining\"]\n",
        "word_embeddings_dict = {}\n",
        "\n",
        "for word in seven_words:\n",
        "  try:\n",
        "    word_embeddings_dict[word] = pretrained_glove_model[word]\n",
        "  except KeyError:\n",
        "    print(f\"Word '{word}' not found in the vocabulary.\")\n",
        "\n",
        "print(\"\\nDictionary of word embeddings:\")\n",
        "print(word_embeddings_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word 'I' not found in the vocabulary.\n",
            "\n",
            "Dictionary of word embeddings:\n",
            "{'love': array([-0.13886  ,  1.1401   , -0.85212  , -0.29212  ,  0.75534  ,\n",
            "        0.82762  , -0.3181   ,  0.0072204, -0.34762  ,  1.0731   ,\n",
            "       -0.24665  ,  0.97765  , -0.55835  , -0.090318 ,  0.83182  ,\n",
            "       -0.33317  ,  0.22648  ,  0.30913  ,  0.026929 , -0.086739 ,\n",
            "       -0.14703  ,  1.3543   ,  0.53695  ,  0.43735  ,  1.2749   ,\n",
            "       -1.4382   , -1.2815   , -0.15196  ,  1.0506   , -0.93644  ,\n",
            "        2.7561   ,  0.58967  , -0.29473  ,  0.27574  , -0.32928  ,\n",
            "       -0.201    , -0.28547  , -0.45987  , -0.14603  , -0.69372  ,\n",
            "        0.070761 , -0.19326  , -0.1855   , -0.16095  ,  0.24268  ,\n",
            "        0.20784  ,  0.030924 , -1.3711   , -0.28606  ,  0.2898   ],\n",
            "      dtype=float32), 'deep': array([ 0.31445 ,  1.2024  ,  0.066651, -0.20096 , -0.049636,  0.66882 ,\n",
            "       -0.049386,  0.44174 ,  0.1799  , -0.10196 , -0.43674 ,  0.12076 ,\n",
            "       -0.12495 ,  0.43378 , -0.87784 ,  0.010281,  0.54592 , -0.28928 ,\n",
            "       -0.46115 , -0.32058 , -0.69094 ,  0.49733 ,  0.40657 , -0.90062 ,\n",
            "        0.69699 , -1.1536  , -0.12229 ,  1.0657  ,  0.93207 ,  0.20439 ,\n",
            "        3.3004  ,  0.14223 ,  0.46493 ,  0.075359, -0.56755 ,  0.30769 ,\n",
            "       -1.1251  , -0.37871 ,  0.57479 , -0.12629 ,  0.13589 ,  0.10633 ,\n",
            "        0.058432,  0.40321 ,  0.10243 ,  0.12004 ,  0.41383 ,  0.051987,\n",
            "       -0.5835  , -1.1159  ], dtype=float32), 'learning': array([ 0.20461 ,  0.48659 , -0.55308 , -0.27019 ,  0.26336 ,  0.15751 ,\n",
            "       -0.28994 , -0.51824 ,  0.051829,  0.36225 ,  0.37077 ,  0.1322  ,\n",
            "       -0.061377, -0.53606 , -0.34733 , -0.043981, -0.086744,  0.78305 ,\n",
            "        0.41422 ,  0.027996,  0.23433 ,  0.98844 , -0.41049 ,  0.6206  ,\n",
            "        1.3966  , -0.65427 , -0.18221 , -1.0293  , -0.014741, -0.25384 ,\n",
            "        3.227   ,  0.39509 , -0.33042 , -1.229   ,  0.29048 ,  0.33654 ,\n",
            "       -0.24817 ,  0.47105 ,  0.32964 ,  0.23997 ,  0.088302, -0.91779 ,\n",
            "       -0.36671 ,  0.9926  ,  0.2185  , -0.316   ,  1.203   ,  0.2699  ,\n",
            "       -0.14093 ,  0.70785 ], dtype=float32), 'and': array([ 0.26818 ,  0.14346 , -0.27877 ,  0.016257,  0.11384 ,  0.69923 ,\n",
            "       -0.51332 , -0.47368 , -0.33075 , -0.13834 ,  0.2702  ,  0.30938 ,\n",
            "       -0.45012 , -0.4127  , -0.09932 ,  0.038085,  0.029749,  0.10076 ,\n",
            "       -0.25058 , -0.51818 ,  0.34558 ,  0.44922 ,  0.48791 , -0.080866,\n",
            "       -0.10121 , -1.3777  , -0.10866 , -0.23201 ,  0.012839, -0.46508 ,\n",
            "        3.8463  ,  0.31362 ,  0.13643 , -0.52244 ,  0.3302  ,  0.33707 ,\n",
            "       -0.35601 ,  0.32431 ,  0.12041 ,  0.3512  , -0.069043,  0.36885 ,\n",
            "        0.25168 , -0.24517 ,  0.25381 ,  0.1367  , -0.31178 , -0.6321  ,\n",
            "       -0.25028 , -0.38097 ], dtype=float32), 'text': array([ 0.32615  ,  0.36686  , -0.0074905, -0.37553  ,  0.66715  ,\n",
            "        0.21646  , -0.19801  , -1.1001   , -0.42221  ,  0.10574  ,\n",
            "       -0.31292  ,  0.50953  ,  0.55775  ,  0.12019  ,  0.31441  ,\n",
            "       -0.25043  , -1.0637   , -1.3213   ,  0.87798  , -0.24627  ,\n",
            "        0.27379  , -0.51092  ,  0.49324  ,  0.52243  ,  1.1636   ,\n",
            "       -0.75323  , -0.48053  , -0.11259  , -0.54595  , -0.83921  ,\n",
            "        2.9825   , -1.1916   , -0.51958  , -0.39365  , -0.1419   ,\n",
            "       -0.026977 ,  0.66296  ,  0.16574  , -1.1681   ,  0.14443  ,\n",
            "        1.6305   , -0.17216  , -0.17436  , -0.01049  , -0.17794  ,\n",
            "        0.93076  ,  1.0381   ,  0.94266  , -0.14805  , -0.61109  ],\n",
            "      dtype=float32), 'mining': array([-0.40025  , -0.40659  ,  0.0077521,  1.6565   , -0.83026  ,\n",
            "        0.15253  , -0.83816  ,  0.32834  ,  0.44981  ,  0.22079  ,\n",
            "        0.62574  , -0.13907  ,  0.26711  , -0.57841  , -0.52047  ,\n",
            "        0.22798  ,  1.2644   ,  0.67962  , -0.31575  , -0.61989  ,\n",
            "        1.5077   , -0.17723  , -0.5155   , -0.99634  , -0.19396  ,\n",
            "       -0.4598   , -0.71236  , -0.61281  ,  0.62343  ,  0.75497  ,\n",
            "        2.4515   , -1.6625   ,  0.070953 ,  0.094319 ,  0.40127  ,\n",
            "       -0.43486  , -1.2432   , -0.073509 ,  1.1299   ,  0.42682  ,\n",
            "       -0.90602  , -0.60423  ,  1.0386   , -0.34647  ,  0.10747  ,\n",
            "       -0.46145  , -0.93874  ,  0.068166 ,  0.48418  , -1.0277   ],\n",
            "      dtype=float32)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3404e093",
        "outputId": "a2cb9c88-2aa1-403e-9c82-d38ccce09029"
      },
      "source": [
        "# Find the word embedding for \"deep\"\n",
        "deep_embedding = pretrained_glove_model[\"deep\"]\n",
        "print(\"Embedding for 'deep':\")\n",
        "print(deep_embedding)\n",
        "\n",
        "# Find the word embedding for \"text\"\n",
        "text_embedding = pretrained_glove_model[\"text\"]\n",
        "print(\"\\nEmbedding for 'text':\")\n",
        "print(text_embedding)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding for 'deep':\n",
            "[ 0.31445   1.2024    0.066651 -0.20096  -0.049636  0.66882  -0.049386\n",
            "  0.44174   0.1799   -0.10196  -0.43674   0.12076  -0.12495   0.43378\n",
            " -0.87784   0.010281  0.54592  -0.28928  -0.46115  -0.32058  -0.69094\n",
            "  0.49733   0.40657  -0.90062   0.69699  -1.1536   -0.12229   1.0657\n",
            "  0.93207   0.20439   3.3004    0.14223   0.46493   0.075359 -0.56755\n",
            "  0.30769  -1.1251   -0.37871   0.57479  -0.12629   0.13589   0.10633\n",
            "  0.058432  0.40321   0.10243   0.12004   0.41383   0.051987 -0.5835\n",
            " -1.1159  ]\n",
            "\n",
            "Embedding for 'text':\n",
            "[ 0.32615    0.36686   -0.0074905 -0.37553    0.66715    0.21646\n",
            " -0.19801   -1.1001    -0.42221    0.10574   -0.31292    0.50953\n",
            "  0.55775    0.12019    0.31441   -0.25043   -1.0637    -1.3213\n",
            "  0.87798   -0.24627    0.27379   -0.51092    0.49324    0.52243\n",
            "  1.1636    -0.75323   -0.48053   -0.11259   -0.54595   -0.83921\n",
            "  2.9825    -1.1916    -0.51958   -0.39365   -0.1419    -0.026977\n",
            "  0.66296    0.16574   -1.1681     0.14443    1.6305    -0.17216\n",
            " -0.17436   -0.01049   -0.17794    0.93076    1.0381     0.94266\n",
            " -0.14805   -0.61109  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 2**"
      ],
      "metadata": {
        "id": "unu_U0TO9zrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/ColabData/novels_by_hgwells.zip\", \"r\") as file:\n",
        "  src = file.read()\n",
        "  f = src.replace(\"\\n\", \" \")  # Replace the new line character with space"
      ],
      "metadata": {
        "id": "c_rvOEBnyula"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7xkzW-qy-5i",
        "outputId": "d9785411-0ec8-469e-a0ce-dd1a2036d0bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "851d8e03"
      },
      "source": [
        "import zipfile\n",
        "zip_file_path = \"/content/drive/MyDrive/ColabData/novels_by_hgwells.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cd83305",
        "outputId": "b1ea0857-96ce-4bb1-e0a4-c0e73290b869"
      },
      "source": [
        "novel_contents = {}\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    file_list = zip_ref.namelist()\n",
        "    for file_name in file_list:\n",
        "        if file_name.endswith('.txt'):\n",
        "            with zip_ref.open(file_name, 'r') as file:\n",
        "                novel_contents[file_name] = file.read().decode('utf-8')\n",
        "\n",
        "print(f\"Loaded contents of {len(novel_contents)} novels.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded contents of 5 novels.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f9f6df8",
        "outputId": "7604f720-821f-444b-8dcd-fc43a8daf972"
      },
      "source": [
        "# Print the first 500 characters of one of the novels to inspect the markers\n",
        "print(list(novel_contents.values())[0][:500])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿The Project Gutenberg eBook of The Time Machine\r\n",
            "    \r\n",
            "This ebook is for the use of anyone anywhere in the United States and\r\n",
            "most other parts of the world at no cost and with almost no restrictions\r\n",
            "whatsoever. You may copy it, give it away or re-use it under the terms\r\n",
            "of the Project Gutenberg License included with this ebook or online\r\n",
            "at www.gutenberg.org. If you are not located in the United States,\r\n",
            "you will have to check the laws of the country where you are located\r\n",
            "before using this eB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b04a92c",
        "outputId": "e43bc050-ed63-472f-973b-4c34225899aa"
      },
      "source": [
        "cleaned_novel_contents = {}\n",
        "start_marker = \"*** START OF THE PROJECT GUTENBERG EBOOK\"\n",
        "end_marker = \"*** END OF THE PROJECT GUTENBERG EBOOK\"\n",
        "\n",
        "for novel_name, content in novel_contents.items():\n",
        "    start_index = content.find(start_marker)\n",
        "    end_index = content.find(end_marker)\n",
        "\n",
        "    if start_index != -1 and end_index != -1:\n",
        "        cleaned_content = content[start_index + len(start_marker):end_index].strip()\n",
        "        cleaned_novel_contents[novel_name] = cleaned_content\n",
        "    else:\n",
        "        print(f\"Markers not found in {novel_name}. Skipping cleaning.\")\n",
        "\n",
        "print(f\"Cleaned content for {len(cleaned_novel_contents)} novels.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned content for 5 novels.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0332da85",
        "outputId": "b4a08cfd-5460-4ac7-b139-6f942562bcca"
      },
      "source": [
        "combined_text = \"\"\n",
        "for content in cleaned_novel_contents.values():\n",
        "  combined_text += content + \" \"\n",
        "\n",
        "print(f\"Combined text length: {len(combined_text)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined text length: 1928326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "063e77e2",
        "outputId": "2030c978-de5a-4058-fa03-b14e87572d57"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sentences = sent_tokenize(combined_text)\n",
        "print(f\"Number of sentences: {len(sentences)}\")\n",
        "print(\"First 5 sentences:\")\n",
        "for i, sentence in enumerate(sentences[:5]):\n",
        "    print(f\"{i+1}: {sentence}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences: 20162\n",
            "First 5 sentences:\n",
            "1: THE TIME MACHINE ***\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "The Time Machine\r\n",
            "\r\n",
            "An Invention\r\n",
            "\r\n",
            "by H. G. Wells\r\n",
            "\r\n",
            "\r\n",
            "CONTENTS\r\n",
            "\r\n",
            " I Introduction\r\n",
            " II The Machine\r\n",
            " III The Time Traveller Returns\r\n",
            " IV Time Travelling\r\n",
            " V In the Golden Age\r\n",
            " VI The Sunset of Mankind\r\n",
            " VII A Sudden Shock\r\n",
            " VIII Explanation\r\n",
            " IX The Morlocks\r\n",
            " X When Night Came\r\n",
            " XI The Palace of Green Porcelain\r\n",
            " XII In the Darkness\r\n",
            " XIII The Trap of the White Sphinx\r\n",
            " XIV The Further Vision\r\n",
            " XV The Time Traveller’s Return\r\n",
            " XVI After the Story\r\n",
            " Epilogue\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            " I.\n",
            "2: Introduction\r\n",
            "\r\n",
            "\r\n",
            "The Time Traveller (for so it will be convenient to speak of him) was\r\n",
            "expounding a recondite matter to us.\n",
            "3: His pale grey eyes shone and\r\n",
            "twinkled, and his usually pale face was flushed and animated.\n",
            "4: The fire\r\n",
            "burnt brightly, and the soft radiance of the incandescent lights in the\r\n",
            "lilies of silver caught the bubbles that flashed and passed in our\r\n",
            "glasses.\n",
            "5: Our chairs, being his patents, embraced and caressed us rather\r\n",
            "than submitted to be sat upon, and there was that luxurious\r\n",
            "after-dinner atmosphere, when thought runs gracefully free of the\r\n",
            "trammels of precision.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e98398ca",
        "outputId": "1aa6c141-1bcf-4549-aefa-c5ff9ad00aca"
      },
      "source": [
        "tokenized_words = []\n",
        "for sentence in sentences:\n",
        "  tokenized_words.append(word_tokenize(sentence.lower()))\n",
        "\n",
        "print(tokenized_words[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'time', 'machine', '*', '*', '*', 'the', 'time', 'machine', 'an', 'invention', 'by', 'h.', 'g.', 'wells', 'contents', 'i', 'introduction', 'ii', 'the', 'machine', 'iii', 'the', 'time', 'traveller', 'returns', 'iv', 'time', 'travelling', 'v', 'in', 'the', 'golden', 'age', 'vi', 'the', 'sunset', 'of', 'mankind', 'vii', 'a', 'sudden', 'shock', 'viii', 'explanation', 'ix', 'the', 'morlocks', 'x', 'when', 'night', 'came', 'xi', 'the', 'palace', 'of', 'green', 'porcelain', 'xii', 'in', 'the', 'darkness', 'xiii', 'the', 'trap', 'of', 'the', 'white', 'sphinx', 'xiv', 'the', 'further', 'vision', 'xv', 'the', 'time', 'traveller', '’', 's', 'return', 'xvi', 'after', 'the', 'story', 'epilogue', 'i', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79f7bc75",
        "outputId": "f93c7227-6cd3-4552-9f11-570d82d9f941"
      },
      "source": [
        "import re\n",
        "\n",
        "cleaned_tokenized_words = []\n",
        "for sentence in tokenized_words:\n",
        "    cleaned_sentence = [re.sub(r'[^a-z]', '', word) for word in sentence]\n",
        "    cleaned_sentence = [word for word in cleaned_sentence if word]\n",
        "    if cleaned_sentence:\n",
        "        cleaned_tokenized_words.append(cleaned_sentence)\n",
        "\n",
        "print(\"First 5 cleaned and tokenized sentences:\")\n",
        "for i, sentence in enumerate(cleaned_tokenized_words[:5]):\n",
        "    print(f\"{i+1}: {sentence}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 cleaned and tokenized sentences:\n",
            "1: ['the', 'time', 'machine', 'the', 'time', 'machine', 'an', 'invention', 'by', 'h', 'g', 'wells', 'contents', 'i', 'introduction', 'ii', 'the', 'machine', 'iii', 'the', 'time', 'traveller', 'returns', 'iv', 'time', 'travelling', 'v', 'in', 'the', 'golden', 'age', 'vi', 'the', 'sunset', 'of', 'mankind', 'vii', 'a', 'sudden', 'shock', 'viii', 'explanation', 'ix', 'the', 'morlocks', 'x', 'when', 'night', 'came', 'xi', 'the', 'palace', 'of', 'green', 'porcelain', 'xii', 'in', 'the', 'darkness', 'xiii', 'the', 'trap', 'of', 'the', 'white', 'sphinx', 'xiv', 'the', 'further', 'vision', 'xv', 'the', 'time', 'traveller', 's', 'return', 'xvi', 'after', 'the', 'story', 'epilogue', 'i']\n",
            "2: ['introduction', 'the', 'time', 'traveller', 'for', 'so', 'it', 'will', 'be', 'convenient', 'to', 'speak', 'of', 'him', 'was', 'expounding', 'a', 'recondite', 'matter', 'to', 'us']\n",
            "3: ['his', 'pale', 'grey', 'eyes', 'shone', 'and', 'twinkled', 'and', 'his', 'usually', 'pale', 'face', 'was', 'flushed', 'and', 'animated']\n",
            "4: ['the', 'fire', 'burnt', 'brightly', 'and', 'the', 'soft', 'radiance', 'of', 'the', 'incandescent', 'lights', 'in', 'the', 'lilies', 'of', 'silver', 'caught', 'the', 'bubbles', 'that', 'flashed', 'and', 'passed', 'in', 'our', 'glasses']\n",
            "5: ['our', 'chairs', 'being', 'his', 'patents', 'embraced', 'and', 'caressed', 'us', 'rather', 'than', 'submitted', 'to', 'be', 'sat', 'upon', 'and', 'there', 'was', 'that', 'luxurious', 'afterdinner', 'atmosphere', 'when', 'thought', 'runs', 'gracefully', 'free', 'of', 'the', 'trammels', 'of', 'precision']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train CBOW model, min_count= 1 the minumum frequency of a word to be considered, basically = 1 means all words are considered\n",
        "cbow_model = Word2Vec(sentences=cleaned_tokenized_words, min_count=1, vector_size=100, window=5, workers=1, seed=2024)"
      ],
      "metadata": {
        "id": "S-09YKe82-1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing word vectors\n",
        "soldiers_embedding = cbow_model.wv[\"soldiers\"]\n",
        "soldiers_embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz0YJR9b3QTJ",
        "outputId": "8b6fc4d9-16ce-4ab5-f346-30895ad63cd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.16178519,  0.05469715, -0.01928971,  0.0328531 , -0.22459379,\n",
              "       -0.0706311 ,  0.02255885,  0.12726709,  0.11228341,  0.23449261,\n",
              "        0.1657856 , -0.0056017 , -0.03916209, -0.02838366, -0.27611437,\n",
              "        0.07465969, -0.08116902, -0.12110235,  0.02083913,  0.20180307,\n",
              "        0.04779929, -0.18391238,  0.14515735, -0.0799435 , -0.08384396,\n",
              "       -0.10332527, -0.18094124, -0.03637947, -0.25439954, -0.05006322,\n",
              "       -0.10119782, -0.02051347,  0.2453411 , -0.10316004,  0.07523695,\n",
              "        0.08417674, -0.2210605 , -0.09092371, -0.27052045, -0.05366279,\n",
              "        0.06800242,  0.07482928,  0.052819  , -0.04213725,  0.27403298,\n",
              "       -0.14395301, -0.11419918, -0.2096227 , -0.11592767,  0.2918546 ,\n",
              "        0.19008821, -0.03207022,  0.03400819,  0.19807489, -0.03446738,\n",
              "       -0.01334772, -0.07218786, -0.00936576,  0.03069368, -0.09920096,\n",
              "        0.06120434, -0.02218848,  0.0724734 , -0.01242984, -0.30887455,\n",
              "        0.14521377,  0.06082198,  0.10527773,  0.04207381,  0.09619859,\n",
              "        0.06603472, -0.0467536 , -0.05277242,  0.0959677 ,  0.06232229,\n",
              "        0.03918394, -0.07931402, -0.13400985,  0.09600595, -0.14415252,\n",
              "        0.20361811, -0.1315144 , -0.08557117, -0.30851814, -0.09276585,\n",
              "        0.09423509,  0.22531581,  0.20816694,  0.14444518, -0.02326041,\n",
              "       -0.01653666,  0.10536845, -0.02821632,  0.07947447,  0.02618443,\n",
              "        0.00761328, -0.16108383,  0.02691424,  0.19635905, -0.14535765],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "road_embedding = cbow_model.wv[\"road\"]\n",
        "road_embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyVpBkiw4OrA",
        "outputId": "f0b0fa4d-9870-4b4c-f9eb-61a71dfecfe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.8048422 , -0.22151385, -0.29268104,  0.11661944, -0.8069631 ,\n",
              "       -0.61083883,  0.38200718,  0.03895012,  0.37928396,  0.9270499 ,\n",
              "        0.06881159, -0.1049026 ,  0.12013513, -0.15974993, -1.0134203 ,\n",
              "        0.00706525, -0.21737677, -0.17365913,  0.13335393,  0.85245717,\n",
              "        0.02616179, -0.5498717 ,  0.6195085 , -0.56438565, -0.47654885,\n",
              "       -0.47964287, -0.63555723,  0.02446435, -1.0708505 , -0.39189854,\n",
              "       -0.12022678,  0.03234294,  0.52935743, -0.10870365,  0.5737262 ,\n",
              "        0.55267185, -0.6079162 , -0.19415991, -1.2290833 , -0.4559802 ,\n",
              "        0.246574  ,  0.23836598,  0.37951532,  0.09854048,  1.0727681 ,\n",
              "       -0.6294799 , -0.3672469 , -0.5619839 , -0.20663811,  0.74931175,\n",
              "        0.58008814,  0.03619054,  0.3248374 ,  0.7090352 , -0.07818832,\n",
              "       -0.08570602, -0.34578443, -0.28249052, -0.30888987, -0.27520743,\n",
              "        0.02722822, -0.18474957,  0.35193494, -0.11949973, -0.9611936 ,\n",
              "        0.03238992,  0.31066918,  0.16562529,  0.02957443,  0.45765856,\n",
              "       -0.09925812, -0.36852518, -0.23204702,  0.27924007,  0.11275181,\n",
              "        0.10214039, -0.34231758, -0.28675443,  0.72142535, -0.5112058 ,\n",
              "        0.46508408, -0.395616  , -0.01080729, -0.83741754, -0.2968707 ,\n",
              "       -0.08529256,  1.2157665 ,  0.48536414,  0.58114445,  0.21976118,\n",
              "       -0.56764805,  0.66540927, -0.26000285,  0.65699047, -0.25106314,\n",
              "        0.14830646, -0.09681363, -0.24846496,  0.60963565, -0.1021857 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding most similar words\n",
        "similar_words = cbow_model.wv.most_similar(\"road\", topn=10)\n",
        "similar_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nj80MQXJ4XMr",
        "outputId": "f95bd5ef-6371-4897-a490-72494feb2cdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('window', 0.9964198470115662),\n",
              " ('darkness', 0.9946605563163757),\n",
              " ('corner', 0.9941814541816711),\n",
              " ('passage', 0.9928684830665588),\n",
              " ('fence', 0.9927415251731873),\n",
              " ('shadow', 0.9927010536193848),\n",
              " ('sea', 0.9926543235778809),\n",
              " ('edge', 0.9912459850311279),\n",
              " ('chair', 0.9910342693328857),\n",
              " ('tops', 0.9909993410110474)]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Skip Gram model. sg=1 means it is a skip-gram model. If sg=0, it would be a CBOW model.\n",
        "skip_gram_model = Word2Vec(sentences=cleaned_tokenized_words, min_count=1, vector_size=100, window=5, workers=1, seed=2024, sg=1)"
      ],
      "metadata": {
        "id": "udmJKEef4j1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing word vectors\n",
        "soldier_embedding = skip_gram_model.wv[\"soldier\"]\n",
        "soldier_embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGRnfQDf4rZN",
        "outputId": "0bbd62ab-c16b-4932-d9ad-74edcb4c621f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.04530066,  0.09393256,  0.00560581,  0.03300663, -0.19665724,\n",
              "        0.03789129, -0.0560987 ,  0.15727226,  0.02741368,  0.23102896,\n",
              "        0.30535233, -0.03941691, -0.16593166, -0.03851601, -0.18986244,\n",
              "        0.1990439 , -0.16734485, -0.06435407,  0.12213738,  0.23833527,\n",
              "        0.06226468, -0.20127812,  0.07718593, -0.07893607, -0.0591576 ,\n",
              "       -0.10779952, -0.09836062, -0.07802978, -0.22878276,  0.0651363 ,\n",
              "       -0.1082561 , -0.02444301,  0.23847821, -0.12705669,  0.056999  ,\n",
              "        0.02820683, -0.25249746, -0.14130381, -0.2617403 , -0.05171452,\n",
              "        0.01050688,  0.12086827,  0.08267979, -0.13147281,  0.12940075,\n",
              "       -0.08516779, -0.08547816, -0.24207841, -0.24404274,  0.3940482 ,\n",
              "        0.21167968, -0.09845351,  0.01665072,  0.16804336, -0.0945928 ,\n",
              "        0.0340865 , -0.05281272, -0.0451587 ,  0.02978575, -0.08821186,\n",
              "        0.04466206,  0.10643891,  0.01600278,  0.03370802, -0.3313413 ,\n",
              "        0.21871427, -0.03355186,  0.19975601,  0.08759224,  0.04422756,\n",
              "        0.20814136,  0.01554984,  0.07997991,  0.22148275,  0.01383623,\n",
              "        0.06111003, -0.15491879, -0.07312219,  0.02311418, -0.11058426,\n",
              "        0.15336128, -0.15312594, -0.23038346, -0.28510126, -0.02380164,\n",
              "        0.18820293,  0.15073377,  0.26660678,  0.08206825, -0.03985161,\n",
              "        0.01693187, -0.00261926,  0.06363439,  0.00577647,  0.07519368,\n",
              "       -0.06878106, -0.14499314,  0.03044577,  0.18810238, -0.27162126],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing word vectors\n",
        "road_embedding = skip_gram_model.wv[\"road\"]\n",
        "road_embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBLBmiAK40qR",
        "outputId": "961e48ba-8e99-4b2c-9211-94c22c1a9857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.37494496, -0.10525256, -0.04566465,  0.11320145, -0.28942358,\n",
              "       -0.23461069,  0.05096478, -0.15094864, -0.0323011 ,  0.56798196,\n",
              "        0.14253931,  0.11200424, -0.03710081, -0.247821  , -0.5472047 ,\n",
              "       -0.03120772, -0.27977723, -0.13021824,  0.12006868,  0.34603247,\n",
              "        0.21434858, -0.35000607,  0.41060588, -0.38646844, -0.02781211,\n",
              "       -0.4259983 , -0.12879157,  0.10211205, -0.6555139 , -0.13988154,\n",
              "        0.17451698, -0.13673769,  0.39145854, -0.01367603,  0.40492842,\n",
              "        0.2838623 , -0.5025894 , -0.25165242, -0.5849699 , -0.1449533 ,\n",
              "        0.12900944, -0.04574975,  0.4616106 , -0.04752597,  0.3058429 ,\n",
              "       -0.29757082, -0.16302195, -0.31386212,  0.06277255,  0.3796186 ,\n",
              "        0.5085921 ,  0.17188397,  0.13358122,  0.43828207, -0.05344812,\n",
              "       -0.15580447, -0.30028588, -0.12217076, -0.01586013, -0.22788863,\n",
              "        0.08692126, -0.01917251,  0.13465188, -0.12342874, -0.43263727,\n",
              "        0.06306347, -0.17229673,  0.22035004,  0.02800278,  0.11444864,\n",
              "        0.05804474, -0.24241537,  0.01099101,  0.38986492,  0.20096189,\n",
              "        0.00782431, -0.05184076, -0.10671958,  0.19752687, -0.12886693,\n",
              "       -0.00513921, -0.32243687, -0.3420095 , -0.5817191 ,  0.10058106,\n",
              "        0.12874252,  0.6536966 ,  0.22061563,  0.03054021,  0.11075769,\n",
              "       -0.34836775,  0.22420043, -0.19196431,  0.1924485 , -0.03837262,\n",
              "        0.00273547, -0.19893968, -0.21539354,  0.2527382 , -0.23111339],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding most similar words\n",
        "similar_words = skip_gram_model.wv.most_similar(\"road\", topn=10)\n",
        "similar_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtzSB-mq46-3",
        "outputId": "ce732236-30d4-4f4c-f1ec-766dde99512d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('river', 0.964411735534668),\n",
              " ('railway', 0.962736189365387),\n",
              " ('mountain', 0.9499139785766602),\n",
              " ('maybury', 0.947864294052124),\n",
              " ('lane', 0.9474352598190308),\n",
              " ('opposite', 0.9439123272895813),\n",
              " ('main', 0.9438663125038147),\n",
              " ('path', 0.9433651566505432),\n",
              " ('west', 0.9428965449333191),\n",
              " ('meadows', 0.9419018030166626)]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ]
}